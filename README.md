# analysis-of-muon-optimizer-in-llms
Analysis of Muon optimizer in modern Large Language Models.

Any contribution is welcome - you can come up with the best way you can contribute. Some ideas:

- Try different Muon optimizer hyperparameters, what did you learn?
- Try different architecture (heads, layer, dim,…), maybe with different muon hyperparams, how does it scale / behave?
- For those who can write about theory / maths, please do so
- Anything else: bugfixes, ideas, feedback, comparison to other optimizers,…

Anyone with meaningful contribution will be listed as co-author (I still need to determine specific criteria), but don't worry, I will include anyone who contributes meaningfully, and probably have acknowledgements section. 